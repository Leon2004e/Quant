# -*- coding: utf-8 -*-
"""
4_Regime_Builder/Trend_Achse/8.Regime_Report_Excel.py

Input:
  <ROOT>/1_Data_Center/Data/Regime/Performance/Trend/per_regime/<variant_id>/<TF>/<SYMBOL>.csv
  (generated by 7.Performance_Join.py)

Output:
  <ROOT>/1_Data_Center/Data/Regime/Performance/Trend/reports_excel/
      index.xlsx
      <variant_id>/<TF>/<SYMBOL>.xlsx

Creates Excel per regime with:
  - State_Overview (by_state)
  - Hourly_Table (by_state_hour)
  - Hourly_Heatmap (hour_utc x trend_state matrix, conditional formatting)
  - Session_Table (by_state_session)
  - Session_Heatmap (session_block|core x trend_state matrix)
  - Meta

No PDF. Uses openpyxl only.

Install:
  pip install openpyxl
"""

from __future__ import annotations

import argparse
import os
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd

from openpyxl import Workbook
from openpyxl.styles import Font, Alignment
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.utils import get_column_letter
from openpyxl.formatting.rule import ColorScaleRule
from openpyxl.worksheet.worksheet import Worksheet


# =========================
# ROOT / PATHS
# =========================

def find_project_root(start: Path) -> Path:
    cur = start.resolve()
    for p in [cur] + list(cur.parents):
        if (p / "1_Data_Center").exists():
            return p
    return start.resolve().parents[1]


ROOT = find_project_root(Path(__file__))
PERF_DIR = ROOT / "1_Data_Center" / "Data" / "Regime" / "Performance" / "Trend"
PER_REGIME_DIR = PERF_DIR / "per_regime"

REPORT_DIR = PERF_DIR / "reports_excel"
INDEX_XLSX = REPORT_DIR / "index.xlsx"


# =========================
# Helpers
# =========================

def utc_now_str() -> str:
    return datetime.now(timezone.utc).isoformat(timespec="seconds")


def ensure_dir(p: Path) -> None:
    p.mkdir(parents=True, exist_ok=True)


def safe_read_csv(path: Path) -> pd.DataFrame:
    if not path.exists():
        return pd.DataFrame()
    df = pd.read_csv(path)
    return df if not df.empty else pd.DataFrame()


def split_sections(df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
    if df.empty or "section" not in df.columns:
        return {}
    out: Dict[str, pd.DataFrame] = {}
    for sec, g in df.groupby("section"):
        out[str(sec)] = g.drop(columns=["section"]).reset_index(drop=True)
    return out


def state_sort_key(v: int) -> int:
    # bear(-1), neutral(0), bull(1)
    return {-1: 0, 0: 1, 1: 2}.get(int(v), 99)


def to_numeric_safe(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df


def autofit_worksheet(ws: Worksheet, max_width: int = 48) -> None:
    # crude autofit: based on string length
    for col_cells in ws.columns:
        col_letter = get_column_letter(col_cells[0].column)
        best = 8
        for cell in col_cells:
            if cell.value is None:
                continue
            try:
                ln = len(str(cell.value))
            except Exception:
                ln = 0
            if ln > best:
                best = ln
        ws.column_dimensions[col_letter].width = min(max_width, best + 2)


def set_header_style(ws: Worksheet, header_row: int = 1) -> None:
    for cell in ws[header_row]:
        cell.font = Font(bold=True)
        cell.alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)
    ws.freeze_panes = ws["A2"]


def write_df(ws: Worksheet, df: pd.DataFrame, start_row: int = 1, start_col: int = 1, header: bool = True) -> Tuple[int, int]:
    r0 = start_row
    c0 = start_col

    rows = dataframe_to_rows(df, index=False, header=header)
    r = r0
    for row in rows:
        c = c0
        for v in row:
            ws.cell(row=r, column=c, value=v)
            c += 1
        r += 1

    nrows = r - r0
    ncols = df.shape[1]
    if header:
        set_header_style(ws, header_row=r0)
    return nrows, ncols


def format_numbers(ws: Worksheet, df: pd.DataFrame, start_row: int, start_col: int) -> None:
    # Applies numeric formats columnwise based on column name.
    # start_row points to header row.
    colnames = list(df.columns)
    for j, name in enumerate(colnames, start=start_col):
        fmt = None
        if name in ("mean_ret", "sum_ret"):
            fmt = "0.000000"
        elif name in ("vol_ret",):
            fmt = "0.000000"
        elif name in ("sharpe",):
            fmt = "0.000"
        elif name in ("hitrate",):
            fmt = "0.000"
        elif name in ("n",):
            fmt = "0"
        elif "hour" in name:
            fmt = "0"
        elif "core" in name:
            fmt = "0"

        if fmt is None:
            continue

        # data starts at start_row+1
        for i in range(start_row + 1, start_row + 1 + len(df)):
            ws.cell(row=i, column=j).number_format = fmt


def apply_heatmap_colors(ws: Worksheet, top_row: int, left_col: int, nrows: int, ncols: int) -> None:
    # Applies a 3-color scale to the numeric block.
    # Expects the top_row/left_col refer to first data cell (not header/labels).
    if nrows <= 0 or ncols <= 0:
        return
    start = f"{get_column_letter(left_col)}{top_row}"
    end = f"{get_column_letter(left_col + ncols - 1)}{top_row + nrows - 1}"
    rng = f"{start}:{end}"
    rule = ColorScaleRule(
        start_type="min", start_color="F8696B",   # red
        mid_type="num", mid_value=0, mid_color="FFEB84",  # yellow
        end_type="max", end_color="63BE7B",      # green
    )
    ws.conditional_formatting.add(rng, rule)


def pivot_matrix(df: pd.DataFrame, idx: str, col: str, val: str) -> pd.DataFrame:
    if df.empty:
        return pd.DataFrame()
    if idx not in df.columns or col not in df.columns or val not in df.columns:
        return pd.DataFrame()
    pvt = df.pivot_table(index=idx, columns=col, values=val, aggfunc="mean")
    pvt = pvt.sort_index()

    # sort trend_state columns
    try:
        cols_sorted = sorted(list(pvt.columns), key=lambda x: state_sort_key(int(x)))
        pvt = pvt[cols_sorted]
    except Exception:
        pass

    # nicer column names
    pvt.columns = [f"state_{int(c)}" for c in pvt.columns]
    pvt = pvt.reset_index()
    return pvt


def parse_key_from_path(p: Path) -> Tuple[str, str, str]:
    # .../per_regime/<variant>/<tf>/<symbol>.csv
    symbol = p.stem
    tf = p.parent.name
    variant = p.parent.parent.name
    return variant, tf, symbol


def discover_per_regime_files() -> List[Path]:
    if not PER_REGIME_DIR.exists():
        return []
    return sorted(PER_REGIME_DIR.glob("*/*/*.csv"))


# =========================
# Build one Excel
# =========================

def build_excel(per_regime_csv: Path, out_xlsx: Path) -> Dict[str, object]:
    df = safe_read_csv(per_regime_csv)
    if df.empty:
        raise RuntimeError(f"empty per_regime file: {per_regime_csv}")

    secs = split_sections(df)
    by_state = secs.get("by_state", pd.DataFrame())
    by_hour = secs.get("by_state_hour", pd.DataFrame())
    by_sess = secs.get("by_state_session", pd.DataFrame())

    # normalize numeric
    for d in (by_state, by_hour, by_sess):
        if not d.empty:
            to_numeric_safe(d, ["trend_state", "n", "mean_ret", "vol_ret", "sharpe", "hitrate", "sum_ret", "hour_utc", "session_core"])

    # sort state order
    if not by_state.empty and "trend_state" in by_state.columns:
        by_state = by_state.sort_values("trend_state", key=lambda s: s.map(lambda x: state_sort_key(int(x)))).reset_index(drop=True)

    # clean columns per section (remove irrelevant empty columns)
    def keep_cols(df0: pd.DataFrame, cols: List[str]) -> pd.DataFrame:
        cols2 = [c for c in cols if c in df0.columns]
        return df0[cols2].copy() if cols2 else df0.copy()

    by_state = keep_cols(by_state, ["trend_label", "trend_state", "n", "mean_ret", "vol_ret", "sharpe", "hitrate", "sum_ret"])
    by_hour  = keep_cols(by_hour,  ["trend_label", "trend_state", "hour_utc", "n", "mean_ret", "vol_ret", "sharpe", "hitrate", "sum_ret"])
    by_sess  = keep_cols(by_sess,  ["trend_label", "trend_state", "session_block", "session_core", "n", "mean_ret", "vol_ret", "sharpe", "hitrate", "sum_ret"])

    # heatmap matrices
    hm_hour_mean = pivot_matrix(by_hour, idx="hour_utc", col="trend_state", val="mean_ret")
    hm_hour_n    = pivot_matrix(by_hour, idx="hour_utc", col="trend_state", val="n")

    if not by_sess.empty:
        sess2 = by_sess.copy()
        sess2["session_id"] = sess2["session_block"].astype(str) + "|core=" + sess2["session_core"].astype(int).astype(str)
        hm_sess_mean = pivot_matrix(sess2, idx="session_id", col="trend_state", val="mean_ret")
        hm_sess_n    = pivot_matrix(sess2, idx="session_id", col="trend_state", val="n")
    else:
        hm_sess_mean = pd.DataFrame()
        hm_sess_n = pd.DataFrame()

    # workbook
    wb = Workbook()
    # remove default sheet
    wb.remove(wb.active)

    # Meta
    ws_meta = wb.create_sheet("Meta")
    variant, tf, symbol = parse_key_from_path(per_regime_csv)
    meta_rows = [
        ["variant_id", variant],
        ["tf", tf],
        ["symbol", symbol],
        ["source_csv", str(per_regime_csv)],
        ["generated_utc", utc_now_str()],
    ]
    for r, (k, v) in enumerate(meta_rows, start=1):
        ws_meta.cell(row=r, column=1, value=k).font = Font(bold=True)
        ws_meta.cell(row=r, column=2, value=v)
    ws_meta.column_dimensions["A"].width = 18
    ws_meta.column_dimensions["B"].width = 90

    # State overview
    ws_state = wb.create_sheet("State_Overview")
    if not by_state.empty:
        write_df(ws_state, by_state, start_row=1, start_col=1, header=True)
        format_numbers(ws_state, by_state, start_row=1, start_col=1)
        autofit_worksheet(ws_state)

    # Hourly table
    ws_ht = wb.create_sheet("Hourly_Table")
    if not by_hour.empty:
        # sort for readability: trend_state, hour_utc
        if "trend_state" in by_hour.columns and "hour_utc" in by_hour.columns:
            by_hour = by_hour.sort_values(["trend_state", "hour_utc"]).reset_index(drop=True)
        write_df(ws_ht, by_hour, start_row=1, start_col=1, header=True)
        format_numbers(ws_ht, by_hour, start_row=1, start_col=1)
        autofit_worksheet(ws_ht)

    # Hourly heatmap (mean)
    ws_hm1 = wb.create_sheet("Hourly_Heatmap_mean")
    if not hm_hour_mean.empty:
        # write pivot
        write_df(ws_hm1, hm_hour_mean, start_row=1, start_col=1, header=True)
        format_numbers(ws_hm1, hm_hour_mean, start_row=1, start_col=1)
        autofit_worksheet(ws_hm1)

        # apply heatmap to numeric block (exclude first column = hour_utc)
        nrows = len(hm_hour_mean)
        ncols = hm_hour_mean.shape[1] - 1
        # data starts row 2; numeric starts col 2
        apply_heatmap_colors(ws_hm1, top_row=2, left_col=2, nrows=nrows, ncols=ncols)

    # Hourly heatmap (n)
    ws_hm2 = wb.create_sheet("Hourly_Heatmap_n")
    if not hm_hour_n.empty:
        write_df(ws_hm2, hm_hour_n, start_row=1, start_col=1, header=True)
        format_numbers(ws_hm2, hm_hour_n, start_row=1, start_col=1)
        autofit_worksheet(ws_hm2)
        nrows = len(hm_hour_n)
        ncols = hm_hour_n.shape[1] - 1
        apply_heatmap_colors(ws_hm2, top_row=2, left_col=2, nrows=nrows, ncols=ncols)

    # Session table
    ws_st = wb.create_sheet("Session_Table")
    if not by_sess.empty:
        if "trend_state" in by_sess.columns and "session_block" in by_sess.columns and "session_core" in by_sess.columns:
            by_sess = by_sess.sort_values(["trend_state", "session_block", "session_core"]).reset_index(drop=True)
        write_df(ws_st, by_sess, start_row=1, start_col=1, header=True)
        format_numbers(ws_st, by_sess, start_row=1, start_col=1)
        autofit_worksheet(ws_st)

    # Session heatmap mean
    ws_shm1 = wb.create_sheet("Session_Heatmap_mean")
    if not hm_sess_mean.empty:
        write_df(ws_shm1, hm_sess_mean, start_row=1, start_col=1, header=True)
        format_numbers(ws_shm1, hm_sess_mean, start_row=1, start_col=1)
        autofit_worksheet(ws_shm1, max_width=70)
        nrows = len(hm_sess_mean)
        ncols = hm_sess_mean.shape[1] - 1
        apply_heatmap_colors(ws_shm1, top_row=2, left_col=2, nrows=nrows, ncols=ncols)

    # Session heatmap n
    ws_shm2 = wb.create_sheet("Session_Heatmap_n")
    if not hm_sess_n.empty:
        write_df(ws_shm2, hm_sess_n, start_row=1, start_col=1, header=True)
        format_numbers(ws_shm2, hm_sess_n, start_row=1, start_col=1)
        autofit_worksheet(ws_shm2, max_width=70)
        nrows = len(hm_sess_n)
        ncols = hm_sess_n.shape[1] - 1
        apply_heatmap_colors(ws_shm2, top_row=2, left_col=2, nrows=nrows, ncols=ncols)

    ensure_dir(out_xlsx.parent)
    wb.save(out_xlsx)

    return {"ok": True, "in": str(per_regime_csv), "out": str(out_xlsx)}


# =========================
# Build index.xlsx
# =========================

def build_index(rows: List[Dict[str, str]]) -> None:
    ensure_dir(REPORT_DIR)
    wb = Workbook()
    ws = wb.active
    ws.title = "Index"

    df = pd.DataFrame(rows)
    if df.empty:
        df = pd.DataFrame(columns=["variant_id", "tf", "symbol", "xlsx_path"])

    write_df(ws, df, start_row=1, start_col=1, header=True)
    autofit_worksheet(ws, max_width=120)
    wb.save(INDEX_XLSX)


# =========================
# CLI
# =========================

def parse_args() -> argparse.Namespace:
    ap = argparse.ArgumentParser()
    ap.add_argument("--max-n", type=int, default=0, help="limit number of reports (0=all)")
    return ap.parse_args()


def main() -> None:
    args = parse_args()

    files = discover_per_regime_files()
    if not files:
        raise RuntimeError(f"No per_regime CSV files found under: {PER_REGIME_DIR}")

    if int(args.max_n) > 0:
        files = files[:int(args.max_n)]

    index_rows: List[Dict[str, str]] = []
    counts = {"ok": 0, "error": 0}

    for f in files:
        variant, tf, symbol = parse_key_from_path(f)
        out_xlsx = REPORT_DIR / variant / tf / f"{symbol}.xlsx"
        try:
            build_excel(f, out_xlsx)
            counts["ok"] += 1
            index_rows.append({
                "variant_id": variant,
                "tf": tf,
                "symbol": symbol,
                "xlsx_path": str(out_xlsx),
            })
        except Exception as e:
            counts["error"] += 1
            index_rows.append({
                "variant_id": variant,
                "tf": tf,
                "symbol": symbol,
                "xlsx_path": f"ERROR: {e}",
            })

    build_index(index_rows)

    print("[INFO] reports:", counts)
    print("[DONE] index ->", INDEX_XLSX.resolve())
    print("[DONE] reports dir ->", REPORT_DIR.resolve())


if __name__ == "__main__":
    main()
